{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y7FDxFkpCCX"
      },
      "source": [
        "### Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "V1hBtQIOoKJ8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import random\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "fgg4xZ6HpVPB"
      },
      "outputs": [],
      "source": [
        "text_df = pd.read_csv('fake_or_real_news.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tlBAAeTLqzy7",
        "outputId": "208ff305-697a-4ba2-bfd6-8dede2b58c21"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8476</td>\n",
              "      <td>You Can Smell Hillary’s Fear</td>\n",
              "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10294</td>\n",
              "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
              "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3608</td>\n",
              "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
              "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10142</td>\n",
              "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
              "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
              "      <td>FAKE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>875</td>\n",
              "      <td>The Battle of New York: Why This Primary Matters</td>\n",
              "      <td>It's primary day in New York and front-runners...</td>\n",
              "      <td>REAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              title  \\\n",
              "0   8476                       You Can Smell Hillary’s Fear   \n",
              "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
              "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
              "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
              "4    875   The Battle of New York: Why This Primary Matters   \n",
              "\n",
              "                                                text label  \n",
              "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
              "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
              "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
              "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
              "4  It's primary day in New York and front-runners...  REAL  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JVXR0Z6-q2Rw"
      },
      "outputs": [],
      "source": [
        "text = list(text_df.text.values)\n",
        "joined_text = \" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "-gZEt1chtmbo"
      },
      "outputs": [],
      "source": [
        "partial_text = joined_text[:300000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "GSfGaUItt3Ub"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OjB-gL5TuUvA"
      },
      "outputs": [],
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token:idx for idx, token in enumerate(unique_tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "F8v_XXsYueYd"
      },
      "outputs": [],
      "source": [
        "n_words = 10\n",
        "input_words =  []\n",
        "next_words = []\n",
        "\n",
        "for i in range(len(tokens) - n_words):\n",
        "  input_words.append(tokens[i:i + n_words])\n",
        "  next_words.append(tokens[i + n_words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "OO5dr7lqzxV8"
      },
      "outputs": [],
      "source": [
        "X = np.zeros((len(input_words),n_words,len(unique_tokens)),dtype='bool')\n",
        "y = np.zeros((len(next_words),len(unique_tokens)),dtype='bool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "g1sBhycN1bMn"
      },
      "outputs": [],
      "source": [
        "for i, words in enumerate(input_words):\n",
        "  for j, word in enumerate(words):\n",
        "    X[i, j, unique_token_index[word]] = 1\n",
        "    y[i, unique_token_index[next_words[i]]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "iA8Zs-CG2YK2"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(n_words,len(unique_tokens)),return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bppyx8L73hgM",
        "outputId": "373dbd0d-423a-46b8-b129-a0ec1284b387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "400/400 [==============================] - 50s 119ms/step - loss: 7.1140 - accuracy: 0.0551\n",
            "Epoch 2/50\n",
            "400/400 [==============================] - 45s 113ms/step - loss: 6.9091 - accuracy: 0.0581\n",
            "Epoch 3/50\n",
            "400/400 [==============================] - 43s 109ms/step - loss: 6.9325 - accuracy: 0.0670\n",
            "Epoch 4/50\n",
            "400/400 [==============================] - 42s 105ms/step - loss: 6.9174 - accuracy: 0.0774\n",
            "Epoch 5/50\n",
            "400/400 [==============================] - 42s 106ms/step - loss: 6.9951 - accuracy: 0.0925\n",
            "Epoch 6/50\n",
            "400/400 [==============================] - 42s 105ms/step - loss: 7.0118 - accuracy: 0.1009\n",
            "Epoch 7/50\n",
            "400/400 [==============================] - 43s 106ms/step - loss: 7.8533 - accuracy: 0.0926\n",
            "Epoch 8/50\n",
            "400/400 [==============================] - 42s 106ms/step - loss: 6.8601 - accuracy: 0.1168\n",
            "Epoch 9/50\n",
            "400/400 [==============================] - 42s 105ms/step - loss: 6.7007 - accuracy: 0.1294\n",
            "Epoch 10/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 6.5412 - accuracy: 0.1468\n",
            "Epoch 11/50\n",
            "400/400 [==============================] - 39s 99ms/step - loss: 6.2876 - accuracy: 0.1634\n",
            "Epoch 12/50\n",
            "400/400 [==============================] - 41s 102ms/step - loss: 6.0102 - accuracy: 0.1830\n",
            "Epoch 13/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 5.6726 - accuracy: 0.2069\n",
            "Epoch 14/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 5.3401 - accuracy: 0.2357\n",
            "Epoch 15/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 4.9734 - accuracy: 0.2620\n",
            "Epoch 16/50\n",
            "400/400 [==============================] - 42s 104ms/step - loss: 4.5517 - accuracy: 0.2957\n",
            "Epoch 17/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 4.1343 - accuracy: 0.3357\n",
            "Epoch 18/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 3.7077 - accuracy: 0.3772\n",
            "Epoch 19/50\n",
            "400/400 [==============================] - 41s 103ms/step - loss: 3.2783 - accuracy: 0.4229\n",
            "Epoch 20/50\n",
            "400/400 [==============================] - 41s 104ms/step - loss: 2.8828 - accuracy: 0.4673\n",
            "Epoch 21/50\n",
            "400/400 [==============================] - 42s 104ms/step - loss: 2.5197 - accuracy: 0.5154\n",
            "Epoch 22/50\n",
            "400/400 [==============================] - 42s 105ms/step - loss: 2.1803 - accuracy: 0.5646\n",
            "Epoch 23/50\n",
            "400/400 [==============================] - 42s 106ms/step - loss: 1.8776 - accuracy: 0.6072\n",
            "Epoch 24/50\n",
            "400/400 [==============================] - 42s 104ms/step - loss: 1.6224 - accuracy: 0.6487\n",
            "Epoch 25/50\n",
            "400/400 [==============================] - 42s 105ms/step - loss: 1.4130 - accuracy: 0.6865\n",
            "Epoch 26/50\n",
            "400/400 [==============================] - 42s 105ms/step - loss: 1.2297 - accuracy: 0.7196\n",
            "Epoch 27/50\n",
            "400/400 [==============================] - 42s 106ms/step - loss: 1.0678 - accuracy: 0.7514\n",
            "Epoch 28/50\n",
            "400/400 [==============================] - 42s 106ms/step - loss: 0.9334 - accuracy: 0.7769\n",
            "Epoch 29/50\n",
            "400/400 [==============================] - 48s 120ms/step - loss: 0.8084 - accuracy: 0.8039\n",
            "Epoch 30/50\n",
            "400/400 [==============================] - 49s 122ms/step - loss: 0.7052 - accuracy: 0.8270\n",
            "Epoch 31/50\n",
            "400/400 [==============================] - 49s 122ms/step - loss: 0.6183 - accuracy: 0.8446\n",
            "Epoch 32/50\n",
            "400/400 [==============================] - 49s 123ms/step - loss: 0.5540 - accuracy: 0.8614\n",
            "Epoch 33/50\n",
            "400/400 [==============================] - 52s 131ms/step - loss: 0.5018 - accuracy: 0.8713\n",
            "Epoch 34/50\n",
            "400/400 [==============================] - 52s 131ms/step - loss: 0.4644 - accuracy: 0.8819\n",
            "Epoch 35/50\n",
            "400/400 [==============================] - 53s 134ms/step - loss: 0.4232 - accuracy: 0.8923\n",
            "Epoch 36/50\n",
            "400/400 [==============================] - 53s 132ms/step - loss: 0.3888 - accuracy: 0.9007\n",
            "Epoch 37/50\n",
            "400/400 [==============================] - 53s 134ms/step - loss: 0.3744 - accuracy: 0.9017\n",
            "Epoch 38/50\n",
            "400/400 [==============================] - 53s 133ms/step - loss: 0.3551 - accuracy: 0.9093\n",
            "Epoch 39/50\n",
            "400/400 [==============================] - 52s 129ms/step - loss: 0.3259 - accuracy: 0.9145\n",
            "Epoch 40/50\n",
            "400/400 [==============================] - 50s 126ms/step - loss: 0.3132 - accuracy: 0.9190\n",
            "Epoch 41/50\n",
            "400/400 [==============================] - 51s 126ms/step - loss: 0.3116 - accuracy: 0.9181\n",
            "Epoch 42/50\n",
            "400/400 [==============================] - 51s 126ms/step - loss: 0.3044 - accuracy: 0.9205\n",
            "Epoch 43/50\n",
            "400/400 [==============================] - 51s 127ms/step - loss: 0.2947 - accuracy: 0.9222\n",
            "Epoch 44/50\n",
            "400/400 [==============================] - 50s 126ms/step - loss: 0.2890 - accuracy: 0.9227\n",
            "Epoch 45/50\n",
            "400/400 [==============================] - 51s 127ms/step - loss: 0.2901 - accuracy: 0.9231\n",
            "Epoch 46/50\n",
            "400/400 [==============================] - 46s 114ms/step - loss: 0.2770 - accuracy: 0.9254\n",
            "Epoch 47/50\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.2621 - accuracy: 0.9281\n",
            "Epoch 48/50\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.2500 - accuracy: 0.9313\n",
            "Epoch 49/50\n",
            "400/400 [==============================] - 45s 112ms/step - loss: 0.2393 - accuracy: 0.9348\n",
            "Epoch 50/50\n",
            "400/400 [==============================] - 44s 109ms/step - loss: 0.2341 - accuracy: 0.9363\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x18ba285c4c0>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(loss =\"categorical_crossentropy\",optimizer=RMSprop(learning_rate=0.01),metrics=[\"accuracy\"])\n",
        "model.fit(X,y,batch_size=128,epochs=50,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "cpub7T_t4QJh"
      },
      "outputs": [],
      "source": [
        "model.save(\"next_word_prediction.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "lMqLfZWT57AE"
      },
      "outputs": [],
      "source": [
        "def predict_next_word(input_text,n_best):\n",
        "  input_text = input_text.lower()\n",
        "  X = np.zeros((1,n_words, len(unique_tokens)))\n",
        "  for i, word in enumerate(input_text.split()):\n",
        "    X[0, i, unique_token_index[word]] = 1\n",
        "  predictions = model.predict(X)[0]\n",
        "  return np.argpartition(predictions, -n_best)[-n_best:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jzhBrEl8O9-",
        "outputId": "8f38bf39-e172-4a5b-de66-88ce226bb4f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        }
      ],
      "source": [
        "possible = predict_next_word(\"The Park is \",5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9LETUF38Xb1",
        "outputId": "ff459085-b1ec-4bb6-873d-0b01641b84ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['common', 'giving', 'using', 'nuclear', 'three']\n"
          ]
        }
      ],
      "source": [
        "print([unique_tokens[idx] for idx in possible])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r35310UJBkm8"
      },
      "source": [
        "# The below code is for text generation which can be included to the scope of our project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "g4kTSN_a8zt-"
      },
      "outputs": [],
      "source": [
        "def generate_text(input_text, text_length,creativity=3):\n",
        "  word_sequence = input_text.split()\n",
        "  current = 0\n",
        "  for _ in range(text_length):\n",
        "    sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower()))[current: current+n_words]\n",
        "    try:\n",
        "      choice = unique_tokens[random.choice(predict_next_word(sub_sequence,creativity))]\n",
        "    except:\n",
        "      choice = random.choice(unique_tokens)\n",
        "    word_sequence.append(choice)\n",
        "    current+=1\n",
        "  return \" \".join(word_sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2LbtnDwr_2Zk",
        "outputId": "c301761f-f66c-457c-87a2-8728b093960a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 14ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'US tax payers are suffering a lot due to angry machine people chancellor laconia down coup moreno misleading nightlife rendering brooklyn'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_text(\"US tax payers are suffering a lot due to\", 12, 3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
